{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  wrapper code for MNIST experiment\n",
    "  Tianqi Chen\n",
    "\"\"\"\n",
    "import os, struct\n",
    "from array import array as pyarray\n",
    "from numpy import append, array, int8, uint8, zeros\n",
    "import sys\n",
    "import random\n",
    "import nncfg\n",
    "import numpy as np\n",
    "import nnet\n",
    "\n",
    "# load MNIST dataset\n",
    "def load(digits, dataset = \"training\", path = \".\"):\n",
    "    \"\"\"\n",
    "    Loads MNIST files into 3D numpy arrays\n",
    "    Adapted from: http://abel.ee.ucla.edu/cvxopt/_downloads/mnist.py\n",
    "    \"\"\"\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError, \"dataset must be 'testing' or 'training'\"\n",
    "\n",
    "    flbl = open(fname_lbl, 'rb')\n",
    "    magic_nr, size = struct.unpack(\">II\", flbl.read(8))\n",
    "    lbl = pyarray(\"b\", flbl.read())\n",
    "    flbl.close()\n",
    "\n",
    "    fimg = open(fname_img, 'rb')\n",
    "    magic_nr, size, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "    img = pyarray(\"B\", fimg.read())\n",
    "    fimg.close()\n",
    "\n",
    "    ind = [ k for k in xrange(size) if lbl[k] in digits ]\n",
    "    N = len(ind)\n",
    "\n",
    "    images = zeros((N, rows, cols), dtype=uint8)\n",
    "    labels = zeros((N, 1), dtype=int8)\n",
    "    for i in xrange(len(ind)):\n",
    "        images[i] = array(img[ ind[i]*rows*cols : (ind[i]+1)*rows*cols ]).reshape((rows, cols))\n",
    "        labels[i] = lbl[ind[i]]\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# default parameters\n",
    "def cfg_param():\n",
    "    param = nnet.NNParam()\n",
    "    param.init_sigma = 0.01\n",
    "    # input size, for mnist, it is 28*28\n",
    "    param.input_size = 28 * 28\n",
    "    # number of output class\n",
    "    param.num_class = 10\n",
    "    param.eta = 0.1\n",
    "    param.mdecay = 0.1\n",
    "    param.wd = 0.00002\n",
    "    param.batch_size = 500\n",
    "    return param\n",
    "\n",
    "def run_exp( param ):\n",
    "    np.random.seed( param.seed )\n",
    "    net = nncfg.create_net( param )\n",
    "    print 'network configure end, start loading data ...'\n",
    "\n",
    "    # load in data \n",
    "    train_images, train_labels = load( range(10), 'training', param.path_data )\n",
    "    test_images , test_labels  = load( range(10), 'testing' , param.path_data )\n",
    "\n",
    "    # create a batch data\n",
    "    # nbatch: batch size\n",
    "    # doshuffle: True, shuffle the data \n",
    "    # scale: 1.0/256 scale by this factor so all features are in [0,1]\n",
    "    train_xdata, train_ylabel  = nncfg.create_batch( train_images, train_labels, param.batch_size, True, 1.0/256.0 )\n",
    "    test_xdata , test_ylabel   = nncfg.create_batch( test_images , test_labels, param.batch_size, True, 1.0/256.0 )\n",
    "    \n",
    "    # split validation set\n",
    "    ntrain = train_xdata.shape[0]    \n",
    "    nvalid = 10000\n",
    "    assert nvalid % param.batch_size == 0\n",
    "    nvalid = nvalid / param.batch_size\n",
    "    valid_xdata, valid_ylabel = train_xdata[0:nvalid], train_ylabel[0:nvalid]\n",
    "    train_xdata, train_ylabel = train_xdata[nvalid:ntrain], train_ylabel[nvalid:ntrain]\n",
    "    \n",
    "    # setup evaluator\n",
    "    evals = []\n",
    "    evals.append( nnet.NNEvaluator( net, train_xdata, train_ylabel, param, 'train' ))\n",
    "    evals.append( nnet.NNEvaluator( net, valid_xdata, valid_ylabel, param, 'valid' ))\n",
    "    evals.append( nnet.NNEvaluator( net, test_xdata ,  test_ylabel, param, 'test'  ))    \n",
    "    \n",
    "    # set parameters\n",
    "    param.num_train = train_ylabel.size\n",
    "    print 'loading end,%d train,%d valid,%d test, start update ...' % ( train_ylabel.size, valid_ylabel.size, test_ylabel.size )\n",
    "        \n",
    "    for it in xrange( param.num_round ):\n",
    "        param.set_round( it )\n",
    "        net.update_all( train_xdata, train_ylabel )\n",
    "        sys.stderr.write( '[%d]' % it )\n",
    "        for ev in evals:\n",
    "            ev.eval( it, sys.stderr )\n",
    "        sys.stderr.write('\\n')            \n",
    "    print 'all update end'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
